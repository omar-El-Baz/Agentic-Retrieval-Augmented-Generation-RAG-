{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0ec290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/bin/python3\n",
      "2.19.0\n",
      "3.9.2\n",
      "2.19.0\n",
      "OPENAI_API_KEY loaded successfully (from environment or .env file).\n",
      "NLTK 'punkt' resource found.\n",
      "NLTK 'punkt_tab' resource found.\n",
      "Dataset 'tripadvisor_hotel_reviews.csv' loaded successfully. Shape: (20491, 2)\n",
      "Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20491 entries, 0 to 20490\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Review  20491 non-null  object\n",
      " 1   Rating  20491 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 320.3+ KB\n",
      "\n",
      "First 5 rows of the dataset:\n",
      "                                              Review  Rating\n",
      "0  nice hotel expensive parking got good deal sta...       4\n",
      "1  ok nothing special charge diamond member hilto...       2\n",
      "2  nice rooms not 4* experience hotel monaco seat...       3\n",
      "3  unique, great stay, wonderful time hotel monac...       5\n",
      "4  great stay great stay, went seahawk game aweso...       5\n",
      "\n",
      "Cleaning reviews...\n",
      "Cleaned reviews (sample of original vs cleaned):\n",
      "                                              Review  \\\n",
      "0  nice hotel expensive parking got good deal sta...   \n",
      "1  ok nothing special charge diamond member hilto...   \n",
      "2  nice rooms not 4* experience hotel monaco seat...   \n",
      "3  unique, great stay, wonderful time hotel monac...   \n",
      "4  great stay great stay, went seahawk game aweso...   \n",
      "\n",
      "                                      cleaned_review  \n",
      "0  nicehotelexpensiveparkinggotgooddealstayhotela...  \n",
      "1  oknothingspecialchargediamondmemberhiltondecid...  \n",
      "2  niceroomsnot4experiencehotelmonacoseattlegoodh...  \n",
      "3  unique,greatstay,wonderfultimehotelmonaco,loca...  \n",
      "4  greatstaygreatstay,wentseahawkgameawesome,down...  \n",
      "\n",
      "Creating document chunks with metadata...\n",
      "Created 20494 document chunks for indexing.\n",
      "Example document structure:\n",
      "{\n",
      "  \"id\": \"73e21cb4-72f0-4005-a36e-db3df578ca68\",\n",
      "  \"content\": \"nicehotelexpensiveparkinggotgooddealstayhotelanniversary,arrivedlateeveningtookadvicepreviousreviewsdidvaletparking,checkquickeasy,littledisappointednonexistentviewroomroomcleannicesize,bedcomfortablewokestiffneckhighpillows,notsoundprooflikeheardmusicroomnightmorningloudbangsdoorsopeningclosinghearpeopletalkinghallway,maybejustnoisyneighbors,avedabathproductsnice,didnotgoldfishstaynicetouchtakenadvantagestayinglonger,locationgreatwalkingdistanceshopping,overallniceexperiencehavingpay40parkingnight,\",\n",
      "  \"metadata\": {\n",
      "    \"original_review_id\": 0,\n",
      "    \"source\": \"tripadvisor_review_0\",\n",
      "    \"chunk_sequential_id_in_review\": 0,\n",
      "    \"rating\": 4,\n",
      "    \"timestamp_processed\": \"2025-05-29T23:32:23.656795\",\n",
      "    \"category\": \"hotel_review\"\n",
      "  }\n",
      "}\n",
      "\n",
      "Saving processed documents to processed_docs.json and processed_docs.csv...\n",
      "Successfully saved to processed_docs.json\n",
      "Successfully saved to processed_docs.csv\n",
      "\n",
      "Setting up vector indexing...\n",
      "Embedding model 'all-MiniLM-L6-v2' loaded.\n",
      "Qdrant client initialized (in-memory).\n",
      "Detected vector size for embeddings: 384\n",
      "Qdrant collection 'travel_guide_rag_collection_v2' created/recreated.\n",
      "Generating embeddings for 20494 content chunks... (This may take a while)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wy/jv928wvn2gv7wnyyzcr4lmch0000gn/T/ipykernel_34163/899726035.py:250: DeprecationWarning: `recreate_collection` method is deprecated and will be removed in the future. Use `collection_exists` to check collection existence and `create_collection` instead.\n",
      "  qdrant_client_instance.recreate_collection(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8802416d0f44220bb2afd1dbaa3f9a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/641 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings generated.\n",
      "Upserting 20494 points to Qdrant collection 'travel_guide_rag_collection_v2'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wy/jv928wvn2gv7wnyyzcr4lmch0000gn/T/ipykernel_34163/899726035.py:272: UserWarning: Local mode is not recommended for collections with more than 20,000 points. Current collection contains 20494 points. Consider using Qdrant in Docker or Qdrant Cloud for better performance with large datasets.\n",
      "  qdrant_client_instance.upsert(collection_name=qdrant_collection_name, points=points_to_upsert, wait=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upsert complete.\n",
      "Collection 'travel_guide_rag_collection_v2' now contains 20494 points.\n",
      "`search_vector_db` function defined for retrieving documents.\n",
      "\n",
      "--- Testing `search_vector_db` function ---\n",
      "Test Query: \"hotel with excellent spa facilities and city view\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wy/jv928wvn2gv7wnyyzcr4lmch0000gn/T/ipykernel_34163/899726035.py:307: DeprecationWarning: `search` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  search_hits = qdrant_client_instance.search(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 results for test query:\n",
      "  Result 1: ID: 48972d80-17af-4ce8-816c-9cbd01aa1452, Score: 0.6264\n",
      "    Content (snippet): greatplace,hotelstreetfrancatrainstationgreattravellingtrain,closemaincentrebeachesshopssiteswalkingdistance,hotelcleane...\n",
      "    Metadata (source): tripadvisor_review_10146\n",
      "  Result 2: ID: 1b2ccb87-89b2-4f51-8ea7-f1c805750f33, Score: 0.6082\n",
      "    Content (snippet): bestbestreasonaffordablebetterhotelscityseattle,greattimestaygreatservicefriendlyemployees,locationconvenientparkingchea...\n",
      "    Metadata (source): tripadvisor_review_20473\n",
      "OpenAI LLM for CrewAI initialized (gpt-3.5-turbo-0125).\n",
      "\n",
      "`search_vector_db` function from Member A's work is available.\n",
      "VectorDBQueryToolForCrew (CrewAI tool) created successfully.\n",
      "\n",
      "--- Testing the CrewAI Tool directly ---\n",
      "Tool Test Query: 'any good hotels in downtown with a gym and free breakfast?'\n",
      "Using Tool: Travel Information Vector Database Query Tool\n",
      "[VectorDBQueryToolForCrew._run] Received query for DB search: 'any good hotels in downtown with a gym and free breakfast?'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wy/jv928wvn2gv7wnyyzcr4lmch0000gn/T/ipykernel_34163/899726035.py:307: DeprecationWarning: `search` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  search_hits = qdrant_client_instance.search(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool Retrieved Info (first 600 chars):\n",
      "Retrieved Information Snippets (Format: [Source, Rating, Relevance Score] Content):\n",
      "Snippet 1: [tripadvisor_review_4248, Rating: 5, Score: 0.517] greathotellocationstayednightweekaugust,hotelcleanbeautiful,locationgreatrighteatoncentre,easyconnectionsubwayeasywalkdowntown,parkcarforgetit.alittlepriceyvacationerroom240taxesbeatsstayingoutsidecitybuckingtrafficmakingquestionablereservationhotelcitynotfeelsecure.go,...\n",
      "---\n",
      "Snippet 2: [tripadvisor_review_2368, Rating: 5, Score: 0.506] greathotel,stayed5daybreak,roomtowersgreatview,hotelstaffpoliteroomscleangreatlocation,...\n",
      "---\n",
      "Snippet 3: [tripadv...\n",
      "\n",
      "Defining CrewAI agents...\n",
      "CrewAI Retriever Agent defined.\n",
      "CrewAI Summarizer Agent defined.\n",
      "CrewAI Composer Agent defined.\n",
      "`get_travel_recommendation_crewai` function defined and ready for use.\n",
      "\n",
      "--- Running CrewAI Demo with Example Query 1 ---\n",
      "\n",
      "--- Initiating CrewAI Process for Query: 'I want to find a quiet, charming boutique hotel in Paris, preferably in the Latin Quarter or Marais, with good reviews for cleanliness.' ---\n",
      "\n",
      "Kicking off the CrewAI travel recommendation process...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">╭──────────────────────────────────────────── Crew Execution Started ─────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">│</span>                                                                                                                 <span style=\"color: #008080; text-decoration-color: #008080\">│</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">│</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Crew Execution Started</span>                                                                                         <span style=\"color: #008080; text-decoration-color: #008080\">│</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Name: </span><span style=\"color: #008080; text-decoration-color: #008080\">crew</span>                                                                                                     <span style=\"color: #008080; text-decoration-color: #008080\">│</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">ID: </span><span style=\"color: #008080; text-decoration-color: #008080\">b70da925-b6ba-47f5-8d81-0a326e0b3321</span>                                                                       <span style=\"color: #008080; text-decoration-color: #008080\">│</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">│</span>                                                                                                                 <span style=\"color: #008080; text-decoration-color: #008080\">│</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">│</span>                                                                                                                 <span style=\"color: #008080; text-decoration-color: #008080\">│</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[36m╭─\u001b[0m\u001b[36m───────────────────────────────────────────\u001b[0m\u001b[36m Crew Execution Started \u001b[0m\u001b[36m────────────────────────────────────────────\u001b[0m\u001b[36m─╮\u001b[0m\n",
       "\u001b[36m│\u001b[0m                                                                                                                 \u001b[36m│\u001b[0m\n",
       "\u001b[36m│\u001b[0m  \u001b[1;36mCrew Execution Started\u001b[0m                                                                                         \u001b[36m│\u001b[0m\n",
       "\u001b[36m│\u001b[0m  \u001b[37mName: \u001b[0m\u001b[36mcrew\u001b[0m                                                                                                     \u001b[36m│\u001b[0m\n",
       "\u001b[36m│\u001b[0m  \u001b[37mID: \u001b[0m\u001b[36mb70da925-b6ba-47f5-8d81-0a326e0b3321\u001b[0m                                                                       \u001b[36m│\u001b[0m\n",
       "\u001b[36m│\u001b[0m                                                                                                                 \u001b[36m│\u001b[0m\n",
       "\u001b[36m│\u001b[0m                                                                                                                 \u001b[36m│\u001b[0m\n",
       "\u001b[36m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\"># Agent:</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">Travel Information Retrieval Specialist</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;95m# Agent:\u001b[0m \u001b[1;92mTravel Information Retrieval Specialist\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">## Task:</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">A user is asking the following travel-related question: 'I want to find a quiet, charming boutique hotel </span>\n",
       "<span style=\"color: #00ff00; text-decoration-color: #00ff00\">in Paris, preferably in the Latin Quarter or Marais, with good reviews for cleanliness.'. Your primary objective is</span>\n",
       "<span style=\"color: #00ff00; text-decoration-color: #00ff00\">to use the 'Travel Information Vector Database Query Tool' by providing it with this exact query: 'I want to find a</span>\n",
       "<span style=\"color: #00ff00; text-decoration-color: #00ff00\">quiet, charming boutique hotel in Paris, preferably in the Latin Quarter or Marais, with good reviews for </span>\n",
       "<span style=\"color: #00ff00; text-decoration-color: #00ff00\">cleanliness.'. Ensure you extract all relevant text snippets from the database that could help answer this query.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[95m## Task:\u001b[0m \u001b[92mA user is asking the following travel-related question: 'I want to find a quiet, charming boutique hotel \u001b[0m\n",
       "\u001b[92min Paris, preferably in the Latin Quarter or Marais, with good reviews for cleanliness.'. Your primary objective is\u001b[0m\n",
       "\u001b[92mto use the 'Travel Information Vector Database Query Tool' by providing it with this exact query: 'I want to find a\u001b[0m\n",
       "\u001b[92mquiet, charming boutique hotel in Paris, preferably in the Latin Quarter or Marais, with good reviews for \u001b[0m\n",
       "\u001b[92mcleanliness.'. Ensure you extract all relevant text snippets from the database that could help answer this query.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d012ff2451247ce837e87f79883f53f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Content of file: m 1.ipynb\n",
    "\n",
    "# \"\"\"\n",
    "# # Agentic RAG Travel Guide Chatbot - Core Logic Notebook\n",
    "#\n",
    "# This notebook contains the consolidated work for:\n",
    "# - **Member A:** Data Ingestion, Preprocessing, Vectorization, and Vector DB Setup.\n",
    "# - **Member B:** CrewAI Agent Orchestration & LLM Integration.\n",
    "#\n",
    "# Run cells sequentially. Ensure `tripadvisor_hotel_reviews.csv` is in the same directory and your `OPENAI_API_KEY` is set as an environment variable or in the relevant cell (using a `.env` file is recommended for security).\n",
    "# \"\"\"\n",
    "\n",
    "# \"\"\"\n",
    "# ## Part 0: Initial Setup - Environment Variables & Imports\n",
    "# \"\"\"\n",
    "\n",
    "# --- CODE CELL (id: initial_setup_env_imports_v2) ---\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import sys\n",
    "import uuid\n",
    "print(sys.executable)\n",
    "import tensorflow\n",
    "print(tensorflow.__version__)\n",
    "import keras\n",
    "print(keras.__version__)\n",
    "import tf_keras\n",
    "print(tf_keras.__version__)\n",
    "\n",
    "# Load environment variables from .env file (especially OPENAI_API_KEY)\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "if not OPENAI_API_KEY:\n",
    "    print(\"WARNING: OPENAI_API_KEY not found in environment variables or .env file.\")\n",
    "    print(\"CrewAI agents (Member B's part) will not function correctly without it.\")\n",
    "    print(\"Please create a .env file in the root directory with: OPENAI_API_KEY='sk-your_key_here'\")\n",
    "else:\n",
    "    print(\"OPENAI_API_KEY loaded successfully (from environment or .env file).\")\n",
    "# --- END CODE CELL ---\n",
    "\n",
    "# \"\"\"\n",
    "# ## Part 1: Member A - Data Ingestion & Vector DB Setup\n",
    "# \"\"\"\n",
    "\n",
    "# \"\"\"\n",
    "# ### 1.1. Imports for Data Ingestion & NLTK Setup\n",
    "# \"\"\"\n",
    "\n",
    "# --- CODE CELL (id: member_a_cell_1_imports_nltk_v2) ---\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "import json\n",
    "# os already imported\n",
    "\n",
    "# Download NLTK data (punkt for sentence tokenization, punkt_tab for specific language data)\n",
    "def download_nltk_resource(resource_name, resource_path):\n",
    "    try:\n",
    "        nltk.data.find(resource_path)\n",
    "        print(f\"NLTK '{resource_name}' resource found.\")\n",
    "    except LookupError:\n",
    "        print(f\"NLTK '{resource_name}' resource not found. Downloading...\")\n",
    "        nltk.download(resource_name, quiet=True)\n",
    "        print(f\"NLTK '{resource_name}' downloaded.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error checking/downloading NLTK '{resource_name}': {e}\")\n",
    "\n",
    "download_nltk_resource('punkt', 'tokenizers/punkt')\n",
    "download_nltk_resource('punkt_tab', 'tokenizers/punkt_tab')\n",
    "# --- END CODE CELL ---\n",
    "\n",
    "# \"\"\"\n",
    "# ### 1.2. Load Dataset\n",
    "# \"\"\"\n",
    "\n",
    "# --- CODE CELL (id: member_a_cell_2_load_data_v2) ---\n",
    "dataset_path = \"tripadvisor_hotel_reviews.csv\"\n",
    "df = pd.DataFrame() # Initialize as empty\n",
    "\n",
    "if not os.path.exists(dataset_path):\n",
    "    print(f\"ERROR: Dataset file not found at {dataset_path}\")\n",
    "    print(\"Please download it from Kaggle (e.g., https://www.kaggle.com/datasets/andrewmvd/trip-advisor-hotel-reviews) and place it in the same directory as this notebook.\")\n",
    "else:\n",
    "    try:\n",
    "        df = pd.read_csv(dataset_path)\n",
    "        print(f\"Dataset '{dataset_path}' loaded successfully. Shape: {df.shape}\")\n",
    "        if not df.empty:\n",
    "          print(\"Dataset Info:\")\n",
    "          df.info()\n",
    "          print(\"\\nFirst 5 rows of the dataset:\")\n",
    "          print(df.head())\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading dataset '{dataset_path}': {e}\")\n",
    "# --- END CODE CELL ---\n",
    "\n",
    "# \"\"\"\n",
    "# ### 1.3. Preprocessing: Clean and Chunk Text\n",
    "# \"\"\"\n",
    "\n",
    "# --- CODE CELL (id: member_a_cell_3_preprocess_v2) ---\n",
    "def clean_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    text = BeautifulSoup(text, \"html.parser\").get_text()\n",
    "    # For JSON strings, backslashes in regex need to be double-escaped: \\\\\\\\ instead of \\\\\n",
    "    text = re.sub(r'[^A-Za-z0-9\\\\s,.!?\\\\\\'\\\"]', '', text) # Allowing basic punctuation including ' and \"\n",
    "    text = re.sub(r'\\\\s+', ' ', text).strip()  # For JSON: \\\\s became \\\\\\\\s\n",
    "    return text\n",
    "\n",
    "if not df.empty and 'Review' in df.columns:\n",
    "    print(\"\\nCleaning reviews...\")\n",
    "    df['cleaned_review'] = df['Review'].apply(clean_text)\n",
    "    print(\"Cleaned reviews (sample of original vs cleaned):\")\n",
    "    print(df[['Review', 'cleaned_review']].head())\n",
    "elif df.empty:\n",
    "    print(\"DataFrame is empty, skipping review cleaning.\")\n",
    "else:\n",
    "    print(\"Column 'Review' not found in DataFrame, skipping review cleaning.\")\n",
    "\n",
    "def chunk_text(text, max_tokens=450):\n",
    "    if not isinstance(text, str) or not text.strip():\n",
    "        return []\n",
    "\n",
    "    sentences = nltk.sent_tokenize(text)\n",
    "    chunks = []\n",
    "    current_chunk_sentences = []\n",
    "    current_token_count = 0\n",
    "\n",
    "    for sentence in sentences:\n",
    "        sentence_tokens = nltk.word_tokenize(sentence)\n",
    "        token_count_for_sentence = len(sentence_tokens)\n",
    "\n",
    "        if token_count_for_sentence > max_tokens:\n",
    "            if current_chunk_sentences:\n",
    "                chunks.append(\" \".join(current_chunk_sentences))\n",
    "                current_chunk_sentences = []\n",
    "                current_token_count = 0\n",
    "\n",
    "            start = 0\n",
    "            while start < token_count_for_sentence:\n",
    "                sub_sentence_tokens = sentence_tokens[start : start + max_tokens]\n",
    "                chunks.append(\" \".join(sub_sentence_tokens))\n",
    "                start += max_tokens\n",
    "            continue\n",
    "\n",
    "        if current_token_count + token_count_for_sentence <= max_tokens:\n",
    "            current_chunk_sentences.append(sentence)\n",
    "            current_token_count += token_count_for_sentence\n",
    "        else:\n",
    "            if current_chunk_sentences:\n",
    "                chunks.append(\" \".join(current_chunk_sentences))\n",
    "            current_chunk_sentences = [sentence]\n",
    "            current_token_count = token_count_for_sentence\n",
    "\n",
    "    if current_chunk_sentences:\n",
    "        chunks.append(\" \".join(current_chunk_sentences))\n",
    "\n",
    "    return [chunk for chunk in chunks if chunk.strip()]\n",
    "# --- END CODE CELL ---\n",
    "\n",
    "# \"\"\"\n",
    "# ### 1.4. Create Documents with Metadata & Save\n",
    "# \"\"\"\n",
    "\n",
    "# --- CODE CELL (id: member_a_cell_4_create_docs_save_v2) ---\n",
    "documents_for_indexing = []\n",
    "if not df.empty and 'cleaned_review' in df.columns and 'Rating' in df.columns:\n",
    "    print(\"\\nCreating document chunks with metadata...\")\n",
    "    for idx, row in df.iterrows():\n",
    "        cleaned_review_text = row['cleaned_review']\n",
    "        original_review_identifier = idx\n",
    "        try:\n",
    "            rating_val = int(row[\"Rating\"])\n",
    "        except (ValueError, TypeError):\n",
    "            rating_val = 0\n",
    "\n",
    "        chunks = chunk_text(cleaned_review_text)\n",
    "        for i, chunk_content in enumerate(chunks):\n",
    "            if not chunk_content.strip(): continue\n",
    "\n",
    "            chunk_unique_id = str(uuid.uuid4())\n",
    "\n",
    "            documents_for_indexing.append({\n",
    "                \"id\": chunk_unique_id,\n",
    "                \"content\": chunk_content,\n",
    "                \"metadata\": {\n",
    "                    \"original_review_id\": original_review_identifier,\n",
    "                    \"source\": f\"tripadvisor_review_{original_review_identifier}\",\n",
    "                    \"chunk_sequential_id_in_review\": i,\n",
    "                    \"rating\": rating_val,\n",
    "                    \"timestamp_processed\": datetime.now().isoformat(),\n",
    "                    \"category\": \"hotel_review\"\n",
    "                }\n",
    "            })\n",
    "    print(f\"Created {len(documents_for_indexing)} document chunks for indexing.\")\n",
    "    if documents_for_indexing:\n",
    "        print(\"Example document structure:\")\n",
    "        print(json.dumps(documents_for_indexing[0], indent=2))\n",
    "\n",
    "        processed_json_path = \"processed_docs.json\"\n",
    "        processed_csv_path = \"processed_docs.csv\"\n",
    "\n",
    "        print(f\"\\nSaving processed documents to {processed_json_path} and {processed_csv_path}...\")\n",
    "        try:\n",
    "            with open(processed_json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                json.dump(documents_for_indexing, f, indent=2)\n",
    "            print(f\"Successfully saved to {processed_json_path}\")\n",
    "\n",
    "            df_to_save_data = []\n",
    "            for doc in documents_for_indexing:\n",
    "                flat_doc = {\"id\": doc[\"id\"],\"content\": doc[\"content\"],**doc[\"metadata\"]}\n",
    "                df_to_save_data.append(flat_doc)\n",
    "            pd.DataFrame(df_to_save_data).to_csv(processed_csv_path, index=False, encoding=\"utf-8\")\n",
    "            print(f\"Successfully saved to {processed_csv_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving processed documents: {e}\")\n",
    "else:\n",
    "    print(\"\\nSkipping document creation: DataFrame is empty or required columns ('cleaned_review', 'Rating') are missing.\")\n",
    "    documents_for_indexing = []\n",
    "# --- END CODE CELL ---\n",
    "\n",
    "# \"\"\"\n",
    "# ### 1.5. Vector Indexing & Retrieval Setup\n",
    "# \"\"\"\n",
    "\n",
    "# --- CODE CELL (id: member_a_cell_5_vector_indexing_v2) ---\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from qdrant_client import QdrantClient, models as qdrant_models\n",
    "\n",
    "qdrant_collection_name = \"travel_guide_rag_collection_v2\"\n",
    "qdrant_client_instance = None\n",
    "embedding_model_instance = None\n",
    "\n",
    "if documents_for_indexing:\n",
    "    print(\"\\nSetting up vector indexing...\")\n",
    "    model_name_for_embedding = \"all-MiniLM-L6-v2\"\n",
    "    try:\n",
    "        embedding_model_instance = SentenceTransformer(model_name_for_embedding)\n",
    "        print(f\"Embedding model '{model_name_for_embedding}' loaded.\")\n",
    "\n",
    "        qdrant_client_instance = QdrantClient(\":memory:\")\n",
    "        print(\"Qdrant client initialized (in-memory).\")\n",
    "\n",
    "        vector_size = embedding_model_instance.get_sentence_embedding_dimension()\n",
    "        print(f\"Detected vector size for embeddings: {vector_size}\")\n",
    "\n",
    "        qdrant_client_instance.recreate_collection(\n",
    "            collection_name=qdrant_collection_name,\n",
    "            vectors_config=qdrant_models.VectorParams(size=vector_size, distance=qdrant_models.Distance.COSINE)\n",
    "        )\n",
    "        print(f\"Qdrant collection '{qdrant_collection_name}' created/recreated.\")\n",
    "\n",
    "        content_list = [doc[\"content\"] for doc in documents_for_indexing]\n",
    "        print(f\"Generating embeddings for {len(content_list)} content chunks... (This may take a while)\")\n",
    "        embeddings = embedding_model_instance.encode(content_list, show_progress_bar=True)\n",
    "        print(\"Embeddings generated.\")\n",
    "\n",
    "        points_to_upsert = [\n",
    "            qdrant_models.PointStruct(\n",
    "                id=doc[\"id\"],\n",
    "                vector=embeddings[i].tolist(),\n",
    "                payload={\"text_content\": doc[\"content\"], **doc[\"metadata\"]}\n",
    "            )\n",
    "            for i, doc in enumerate(documents_for_indexing)\n",
    "        ]\n",
    "\n",
    "        if points_to_upsert:\n",
    "            print(f\"Upserting {len(points_to_upsert)} points to Qdrant collection '{qdrant_collection_name}'...\")\n",
    "            qdrant_client_instance.upsert(collection_name=qdrant_collection_name, points=points_to_upsert, wait=True)\n",
    "            print(\"Upsert complete.\")\n",
    "            collection_info = qdrant_client_instance.get_collection(collection_name=qdrant_collection_name)\n",
    "            print(f\"Collection '{qdrant_collection_name}' now contains {collection_info.points_count} points.\")\n",
    "        else:\n",
    "            print(\"No points generated to upsert into Qdrant.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during vector indexing setup or embedding process: {e}\")\n",
    "        qdrant_client_instance = None\n",
    "        embedding_model_instance = None\n",
    "else:\n",
    "    print(\"\\nSkipping vector indexing as no documents were processed or loaded for indexing.\")\n",
    "# --- END CODE CELL ---\n",
    "\n",
    "# \"\"\"\n",
    "# ### 1.6. Retrieval Function (for Member B)\n",
    "# \"\"\"\n",
    "\n",
    "# --- CODE CELL (id: member_a_cell_6_retrieval_func_v2) ---\n",
    "def search_vector_db(query_text: str, top_k: int = 5) -> list[dict]:\n",
    "    if not qdrant_client_instance or not embedding_model_instance:\n",
    "        print(\"ERROR in search_vector_db: Qdrant client or embedding model is not initialized. Cannot perform search.\")\n",
    "        return []\n",
    "    if not query_text or not isinstance(query_text, str):\n",
    "        print(\"ERROR in search_vector_db: Query text is invalid.\")\n",
    "        return []\n",
    "\n",
    "    try:\n",
    "        query_embedding = embedding_model_instance.encode([query_text])[0]\n",
    "    except Exception as e:\n",
    "        print(f\"Error encoding query text in search_vector_db: {e}\")\n",
    "        return []\n",
    "\n",
    "    try:\n",
    "      search_hits = qdrant_client_instance.search(\n",
    "          collection_name=qdrant_collection_name,\n",
    "          query_vector=query_embedding.tolist(),\n",
    "          limit=top_k,\n",
    "          with_payload=True\n",
    "      )\n",
    "    except Exception as e:\n",
    "      print(f\"Error during Qdrant search operation: {e}\")\n",
    "      return []\n",
    "\n",
    "    formatted_search_results = []\n",
    "    for hit in search_hits:\n",
    "        payload = hit.payload if hit.payload else {}\n",
    "        formatted_search_results.append({\n",
    "            \"id\": str(hit.id),\n",
    "            \"score\": float(hit.score),\n",
    "            \"content\": payload.get(\"text_content\", \"\"),\n",
    "            \"metadata\": {k: v for k, v in payload.items() if k != \"text_content\"}\n",
    "        })\n",
    "    return formatted_search_results\n",
    "\n",
    "print(\"`search_vector_db` function defined for retrieving documents.\")\n",
    "\n",
    "if qdrant_client_instance and embedding_model_instance and documents_for_indexing:\n",
    "    try:\n",
    "        collection_info_for_test = qdrant_client_instance.get_collection(collection_name=qdrant_collection_name)\n",
    "        if collection_info_for_test.points_count > 0:\n",
    "            test_search_query = \"hotel with excellent spa facilities and city view\"\n",
    "            print(f\"\\n--- Testing `search_vector_db` function ---\")\n",
    "            print(f\"Test Query: \\\"{test_search_query}\\\"\")\n",
    "            retrieved_search_results = search_vector_db(test_search_query, top_k=2)\n",
    "            if retrieved_search_results:\n",
    "                print(f\"Found {len(retrieved_search_results)} results for test query:\")\n",
    "                for i, res_item in enumerate(retrieved_search_results):\n",
    "                    print(f\"  Result {i+1}: ID: {res_item['id']}, Score: {res_item['score']:.4f}\")\n",
    "                    print(f\"    Content (snippet): {res_item['content'][:120]}...\")\n",
    "                    print(f\"    Metadata (source): {res_item['metadata'].get('source', 'N/A')}\")\n",
    "            else:\n",
    "                print(\"No results found for the test search query or the search operation failed.\")\n",
    "        else:\n",
    "            print(\"Skipping retrieval function test as Qdrant collection is empty.\")\n",
    "    except Exception as e_test_search:\n",
    "        print(f\"Could not perform retrieval function test due to an error: {e_test_search}\")\n",
    "else:\n",
    "    print(\"\\nSkipping retrieval function test: Qdrant client, embedding model, or indexed documents are not ready.\")\n",
    "# --- END CODE CELL ---\n",
    "\n",
    "# \"\"\"\n",
    "# ---\n",
    "#\n",
    "# ## Part 2: Member B - Agent Orchestration & LLM Lead\n",
    "# \"\"\"\n",
    "\n",
    "# \"\"\"\n",
    "# ### 2.1. Imports for CrewAI & LLM Setup\n",
    "# \"\"\"\n",
    "\n",
    "# --- CODE CELL (id: member_b_cell_1_imports_llm_v2) ---\n",
    "from crewai import Agent, Task, Crew, Process\n",
    "from crewai.tools import BaseTool\n",
    "from langchain_openai import ChatOpenAI\n",
    "# os already imported, OPENAI_API_KEY already loaded\n",
    "\n",
    "llm_for_crewai = None\n",
    "\n",
    "if not OPENAI_API_KEY:\n",
    "    print(\"ERROR: OPENAI_API_KEY environment variable not set. CrewAI agents cannot be initialized.\")\n",
    "else:\n",
    "    try:\n",
    "        llm_for_crewai = ChatOpenAI(model_name=\"gpt-3.5-turbo-0125\", temperature=0.2, openai_api_key=OPENAI_API_KEY)\n",
    "        print(\"OpenAI LLM for CrewAI initialized (gpt-3.5-turbo-0125).\")\n",
    "    except Exception as e_llm_init:\n",
    "        print(f\"Error initializing OpenAI LLM for CrewAI: {e_llm_init}. Check your API key and relevant package versions.\")\n",
    "# --- END CODE CELL ---\n",
    "\n",
    "# \"\"\"\n",
    "# ### 2.2. Retrieval Agent Tool Setup\n",
    "# \"\"\"\n",
    "\n",
    "# --- CODE CELL (id: member_b_cell_2_retrieval_tool_v2) ---\n",
    "crewai_vector_db_tool = None\n",
    "try:\n",
    "    search_vector_db\n",
    "    print(\"\\n`search_vector_db` function from Member A's work is available.\")\n",
    "\n",
    "    class VectorDBQueryToolForCrew(BaseTool):\n",
    "        name: str = \"Travel Information Vector Database Query Tool\"\n",
    "        description: str = (\"Use this specialized tool to query the travel vector database. \"\n",
    "                          \"Input MUST be the user's specific query string. \"\n",
    "                          \"The tool will find relevant hotel reviews or travel information snippets.\")\n",
    "\n",
    "        def _run(self, user_query: str) -> str:\n",
    "            if not isinstance(user_query, str) or not user_query.strip():\n",
    "                return \"Error: Invalid input. The user query must be a non-empty string.\"\n",
    "\n",
    "            print(f\"[VectorDBQueryToolForCrew._run] Received query for DB search: '{user_query}'\")\n",
    "            search_results_from_db = search_vector_db(query_text=user_query, top_k=3)\n",
    "\n",
    "            if not search_results_from_db:\n",
    "                return \"No relevant information snippets were found in the database for this specific query.\"\n",
    "\n",
    "            formatted_tool_output = \"Retrieved Information Snippets (Format: [Source, Rating, Relevance Score] Content):\\n\"\n",
    "            for i, res_item in enumerate(search_results_from_db):\n",
    "                content_snippet = res_item.get('content', 'N/A')\n",
    "                metadata_info = res_item.get('metadata', {})\n",
    "                score_val = res_item.get('score', 0.0)\n",
    "                source_info = metadata_info.get('source', 'Unknown')\n",
    "                rating_info = metadata_info.get('rating', 'N/A')\n",
    "                formatted_tool_output += f\"Snippet {i+1}: [{source_info}, Rating: {rating_info}, Score: {score_val:.3f}] {content_snippet[:300]}...\\n---\\n\"\n",
    "            return formatted_tool_output\n",
    "\n",
    "    crewai_vector_db_tool = VectorDBQueryToolForCrew()\n",
    "    print(\"VectorDBQueryToolForCrew (CrewAI tool) created successfully.\")\n",
    "\n",
    "    print(\"\\n--- Testing the CrewAI Tool directly ---\")\n",
    "    test_query_for_crewai_tool_instance = \"any good hotels in downtown with a gym and free breakfast?\"\n",
    "    print(f\"Tool Test Query: '{test_query_for_crewai_tool_instance}'\")\n",
    "    retrieved_info_from_tool_test = crewai_vector_db_tool.run(test_query_for_crewai_tool_instance)\n",
    "    print(f\"Tool Retrieved Info (first 600 chars):\\n{retrieved_info_from_tool_test[:600]}...\")\n",
    "\n",
    "except NameError:\n",
    "    print(\"CRITICAL ERROR: `search_vector_db` function from Member A is not defined. Cannot create CrewAI tool. Please ensure Member A's cells are run successfully first.\")\n",
    "except Exception as e_tool_setup:\n",
    "    print(f\"An unexpected error occurred during CrewAI tool setup: {e_tool_setup}\")\n",
    "# --- END CODE CELL ---\n",
    "\n",
    "# \"\"\"\n",
    "# ### 2.3. Define CrewAI Agents\n",
    "# \"\"\"\n",
    "\n",
    "# --- CODE CELL (id: member_b_cell_3_define_agents_v2) ---\n",
    "crewai_retriever_agent = None\n",
    "crewai_summarizer_agent = None\n",
    "crewai_composer_agent = None\n",
    "\n",
    "if llm_for_crewai and crewai_vector_db_tool:\n",
    "    print(\"\\nDefining CrewAI agents...\")\n",
    "    crewai_retriever_agent = Agent(\n",
    "        role='Travel Information Retrieval Specialist',\n",
    "        goal=(\"Efficiently search the travel vector database using the 'Travel Information Vector Database Query Tool'. \"\n",
    "              \"Your sole objective is to pass the user's query to this tool and return its exact output.\"),\n",
    "        backstory=(\n",
    "            \"You are an AI assistant specialized in data retrieval. You have one tool: 'Travel Information Vector Database Query Tool'.\"\n",
    "            \"When given a user query, you must use this tool by providing the query as input. Do not attempt to answer the query yourself; only use the tool.\"\n",
    "        ),\n",
    "        tools=[crewai_vector_db_tool],\n",
    "        llm=llm_for_crewai,\n",
    "        verbose=True,\n",
    "        allow_delegation=False,\n",
    "        memory=False\n",
    "    )\n",
    "    print(\"CrewAI Retriever Agent defined.\")\n",
    "\n",
    "    crewai_summarizer_agent = Agent(\n",
    "        role='Information Synthesis Expert',\n",
    "        goal=(\"Take the collection of retrieved text snippets (output from the Retriever Agent) and the original user query. \"\n",
    "              \"Identify the most critical information relevant to the query, eliminate redundancy, and produce a concise, factual summary.\"),\n",
    "        backstory=(\n",
    "            \"You are an AI assistant skilled in processing and synthesizing textual information from multiple sources. \"\n",
    "            \"You receive raw text snippets. Your task is to distill these into a coherent summary that directly addresses the user's needs as stated in their original query. Focus on facts and key opinions.\"\n",
    "        ),\n",
    "        llm=llm_for_crewai,\n",
    "        verbose=True,\n",
    "        allow_delegation=False,\n",
    "        memory=False\n",
    "    )\n",
    "    print(\"CrewAI Summarizer Agent defined.\")\n",
    "\n",
    "    crewai_composer_agent = Agent(\n",
    "        role='Travel Recommendation Composer and Advisor',\n",
    "        goal=(\"Generate a helpful, well-formatted, and user-friendly travel recommendation or response. \"\n",
    "              \"This response should be based *only* on the synthesized summary provided by the Summarizer Agent and should directly address the user's original query. \"\n",
    "              \"Adopt a friendly, knowledgeable travel assistant persona.\"),\n",
    "        backstory=(\n",
    "            \"You are a creative and articulate AI travel assistant. You receive a concise summary of relevant information. \"\n",
    "            \"Your responsibility is to craft this summary into an engaging and practical piece of travel advice, an itinerary suggestion, or a direct recommendation. \"\n",
    "            \"Pay close attention to tone (friendly, helpful), clarity, and formatting (e.g., use bullet points, bolding for emphasis if it enhances readability).\"\n",
    "        ),\n",
    "        llm=llm_for_crewai,\n",
    "        verbose=True,\n",
    "        allow_delegation=False,\n",
    "        memory=False\n",
    "    )\n",
    "    print(\"CrewAI Composer Agent defined.\")\n",
    "else:\n",
    "    print(\"\\nSkipping CrewAI agent definitions: LLM for CrewAI or the CrewAI Vector DB Tool is not initialized.\")\n",
    "# --- END CODE CELL ---\n",
    "\n",
    "# \"\"\"\n",
    "# ### 2.4. Define Main Function for Crew Execution (for Member C) & Demo\n",
    "# \"\"\"\n",
    "\n",
    "# --- CODE CELL (id: member_b_cell_4_crew_function_demo_v2) ---\n",
    "def get_travel_recommendation_crewai(user_query: str) -> str:\n",
    "    if not all([crewai_retriever_agent, crewai_summarizer_agent, crewai_composer_agent]):\n",
    "        return \"Error: One or more CrewAI agents are not initialized. Please check the setup and logs.\"\n",
    "    if not isinstance(user_query, str) or not user_query.strip():\n",
    "        return \"Error: User query is invalid (empty or not a string).\"\n",
    "\n",
    "    print(f\"\\n--- Initiating CrewAI Process for Query: '{user_query}' ---\")\n",
    "\n",
    "    retrieval_task = Task(\n",
    "        description=(\n",
    "            f\"A user is asking the following travel-related question: '{user_query}'. \"\n",
    "            f\"Your primary objective is to use the 'Travel Information Vector Database Query Tool' by providing it with this exact query: '{user_query}'. \"\n",
    "            f\"Ensure you extract all relevant text snippets from the database that could help answer this query.\"\n",
    "        ),\n",
    "        expected_output=(\n",
    "            \"A string containing several text snippets retrieved from the vector database via the tool. \"\n",
    "            \"Each snippet should be clearly demarcated. This output will be passed to the Summarizer Agent for further processing.\"\n",
    "        ),\n",
    "        agent=crewai_retriever_agent,\n",
    "    )\n",
    "\n",
    "    summarization_task = Task(\n",
    "        description=(\n",
    "            f\"You have received a collection of retrieved text snippets related to the user's original query: '{user_query}'. \"\n",
    "            f\"Your task is to carefully analyze these snippets, identify the most critical and relevant pieces of information, \"\n",
    "            f\"eliminate any redundancy or irrelevant details, and then synthesize a concise, factual summary. \"\n",
    "            f\"The summary must directly address the key aspects of the user's query.\"\n",
    "        ),\n",
    "        expected_output=(\n",
    "            \"A short, coherent, and neutral summary of the most important facts and opinions extracted from the retrieved texts. \"\n",
    "            \"This summary will be used by the Composer Agent to formulate the final user response.\"\n",
    "        ),\n",
    "        agent=crewai_summarizer_agent,\n",
    "        context=[retrieval_task]\n",
    "    )\n",
    "\n",
    "    composition_task = Task(\n",
    "        description=(\n",
    "            f\"You have received a concise summary of information pertinent to the user's query: '{user_query}'. \"\n",
    "            f\"Your task is to craft a helpful, friendly, and well-formatted travel recommendation or direct answer for the user. \"\n",
    "            f\"Use only the information from the provided summary. Adopt a knowledgeable travel assistant persona. \"\n",
    "            f\"Format the response clearly, using bullet points or paragraphs as appropriate for readability.\"\n",
    "        ),\n",
    "        expected_output=(\n",
    "            \"The final, polished, user-facing response. It should be well-written, directly answer the user's query, \"\n",
    "            \"provide practical recommendations if applicable, and be formatted for easy understanding. This is the ultimate output the user will see.\"\n",
    "        ),\n",
    "        agent=crewai_composer_agent,\n",
    "        context=[summarization_task]\n",
    "    )\n",
    "\n",
    "    travel_recommendation_crew = Crew(\n",
    "        agents=[crewai_retriever_agent, crewai_summarizer_agent, crewai_composer_agent],\n",
    "        tasks=[retrieval_task, summarization_task, composition_task],\n",
    "        process=Process.sequential,\n",
    "        verbose=True,\n",
    "        memory=False\n",
    "    )\n",
    "\n",
    "    print(\"\\nKicking off the CrewAI travel recommendation process...\")\n",
    "    try:\n",
    "        crew_execution_result = travel_recommendation_crew.kickoff()\n",
    "        print(\"CrewAI process execution finished successfully.\")\n",
    "        return str(crew_execution_result)\n",
    "    except Exception as e_crew_kickoff:\n",
    "        print(f\"CRITICAL ERROR during CrewAI kickoff or execution: {e_crew_kickoff}\")\n",
    "        return f\"I'm sorry, an internal error occurred while processing your request with the AI crew. Details: {str(e_crew_kickoff)}\"\n",
    "\n",
    "print(\"`get_travel_recommendation_crewai` function defined and ready for use.\")\n",
    "\n",
    "if all([crewai_retriever_agent, crewai_summarizer_agent, crewai_composer_agent, OPENAI_API_KEY, llm_for_crewai]) :\n",
    "    print(\"\\n--- Running CrewAI Demo with Example Query 1 ---\")\n",
    "    example_user_query_crew_1 = \"I want to find a quiet, charming boutique hotel in Paris, preferably in the Latin Quarter or Marais, with good reviews for cleanliness.\"\n",
    "    final_response_from_crew_1 = get_travel_recommendation_crewai(example_user_query_crew_1)\n",
    "    print(f\"\\n--- Final Response for Query: '{example_user_query_crew_1}' ---\")\n",
    "    print(final_response_from_crew_1)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "    print(\"\\n--- Running CrewAI Demo with Example Query 2 ---\")\n",
    "    example_user_query_crew_2 = \"Suggest some unique cultural experiences or hidden gems in Rome for a solo traveler interested in history but wants to avoid huge crowds.\"\n",
    "    final_response_from_crew_2 = get_travel_recommendation_crewai(example_user_query_crew_2)\n",
    "    print(f\"\\n--- Final Response for Query: '{example_user_query_crew_2}' ---\")\n",
    "    print(final_response_from_crew_2)\n",
    "else:\n",
    "    print(\"\\nSkipping CrewAI demo run: One or more critical components (agents, OpenAI API key, LLM) are not initialized. Please check previous cells for errors.\")\n",
    "# --- END CODE CELL ---\n",
    "\n",
    "# \"\"\"\n",
    "# ---\n",
    "#\n",
    "# End of Core Logic Notebook (Member A & B Tasks).\n",
    "#\n",
    "# The `get_travel_recommendation_crewai(user_query)` function is now ready. Member C can use this function in the Streamlit UI (`app.py`) by either copying the relevant agent/tool/function definitions or by refactoring this notebook's logic into importable Python modules.\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d574a59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
